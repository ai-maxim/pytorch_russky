{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шумоподавляющие автоэнкодеры и что с ними делать\n",
    "\n",
    "В этом примере мы будем обучать глубокие автоэнкодеры и применять их к изображениям лиц, в том числе для поиска похожих.\n",
    "\n",
    "Изображения лиц представлены датасетом [lfw](http://vis-www.cs.umass.edu/lfw/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lfw_dataset import fetch_lfw_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, attr = fetch_lfw_dataset(use_raw=True,dimx=38,dimy=38)\n",
    "X = X.astype('float32') / 256.0\n",
    "\n",
    "img_shape = X.shape[1:]\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('sample image')\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(X[i])\n",
    "\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"attr shape:\",attr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура автоэнкодера\n",
    "\n",
    "Представим автоэнкодер как две последовательных сети: энкодер и декодер.\n",
    "\n",
    "<img src=\"http://nghiaho.com/wp-content/uploads/2012/12/autoencoder_network1.png\" width=640px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первый шаг: PCA\n",
    "\n",
    "Метод главных компонент (Principal component analysis, или PCA) - популярный метод снижения размерности. \n",
    "\n",
    "Основой метода является такое разложение матрицы \"объект-признак\" $X$ на две матрицы меньшего размера: $W$ и $\\hat W$, которое минимизирует _среднеквадратичную ошибку_:\n",
    "\n",
    "$$\\|(X W) \\hat{W} - X\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n",
    "- $X \\in \\mathbb{R}^{n \\times m}$ - Матрица объектов (**центрированная**);\n",
    "- $W \\in \\mathbb{R}^{m \\times d}$ - Матрица прямого преобразования;\n",
    "- $\\hat{W} \\in \\mathbb{R}^{d \\times m}$ - Матрица обратного преобразования;\n",
    "- $n$ - количество примеров, $m$ - оригинальная размерность и $d$ - целевая размерность;\n",
    "\n",
    "В геометрическом смысле, мы хотим выделить $d$ осей, вдоль которых находится большая часть дисперсии. Эти оси также иногда называются \"естественными\".\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/PCA_fish.png/256px-PCA_fish.png)\n",
    "\n",
    "\n",
    "PCA также может быть рассмотрен как особый случай автоэнкодера.\n",
    "\n",
    "* __Энкодер__: X -> Linear(d нейронов) -> код\n",
    "* __Декодер__: код -> Linear(m нейронов) -> X\n",
    "\n",
    "Где Linear обозначает полносвязный слой с линейной активационной функцией:   $f(X) = W \\cdot X + \\vec b $\n",
    "\n",
    "Замечание: в данных слоях смещение предназначено для вычета средного, или \"центрирования\" матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_shape, code_size=32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc = <your code here>\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), -1)\n",
    "        input = self.enc(input)\n",
    "        return input\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, img_shape, code_size=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec = <your code here>\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = self.dec(input)\n",
    "        input = input.view((input.size(0),) + img_shape)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем их в одну модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Here we define a simple linear autoencoder as described above.\n",
    "    We also flatten and un-flatten data to be compatible with image shapes\n",
    "    \"\"\"\n",
    "    def __init__(self, img_shape, code_size=32):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = <your code here>\n",
    "        self.decoder = <your code here>\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = self.encoder(input)\n",
    "        input = self.decoder(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "code_size = 32\n",
    "\n",
    "autoencoder = Autoencoder(img_shape, code_size)\n",
    "\n",
    "inp_image = Variable(torch.FloatTensor((batch_size,) + img_shape))\n",
    "inp_code = Variable(torch.FloatTensor(batch_size, code_size))\n",
    "\n",
    "if use_cuda:\n",
    "    autoencoder.cuda()\n",
    "    inp_image.cuda()\n",
    "    inp_code.cuda()\n",
    "    \n",
    "autoenc_opt = torch.optim.Adamax(autoencoder.parameters())\n",
    "autoenc_loss = <your code here> # mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size = 32, verbose = True):\n",
    "    indices = np.random.permutation(np.arange(len(data)))\n",
    "    batches = range(0, len(data), batch_size)\n",
    "    if verbose: \n",
    "        batches = tqdm(batches)\n",
    "    return (torch.from_numpy(data[indices[start_idx:start_idx + batch_size]]) for start_idx in batches)\n",
    "\n",
    "def compute_loss(x_batch):\n",
    "    autoencoder.eval()\n",
    "    inp_image.data.resize_(x_batch.size()).copy_(x_batch)\n",
    "    rec = autoencoder(inp_image)\n",
    "    err = autoenc_loss(rec, inp_image)\n",
    "    autoencoder.train()\n",
    "    return err.data[0]\n",
    "\n",
    "def evaluate(x):\n",
    "    val_losses = list(map(compute_loss, iterate_minibatches(x,verbose=False)))\n",
    "    return np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(32):\n",
    "    losses = []\n",
    "    for x_batch in iterate_minibatches(X_train,batch_size=batch_size):\n",
    "        autoencoder.zero_grad()\n",
    "        inp_image.data.resize_(x_batch.size()).copy_(x_batch)\n",
    "        rec = autoencoder(inp_image)\n",
    "        err = autoenc_loss(rec, inp_image)\n",
    "        err.backward()\n",
    "        autoenc_opt.step()\n",
    "        losses.append(err.data[0])\n",
    "    print(\"#%i, Train loss: %.7f\"%(epoch+1,np.mean(losses)),flush=True)\n",
    "\n",
    "    print(\"#%i, Test loss: %.7f\"%(epoch+1,evaluate(X_test)),flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize(img,encoder,decoder):\n",
    "    \"\"\"Draws original, encoded and decoded images\"\"\"\n",
    "    inp_image.data.resize_(img[None].shape).copy_(torch.from_numpy(img[None]))\n",
    "    code = encoder(inp_image)\n",
    "    reco = decoder(code).data.numpy()[0]\n",
    "    code = code.data.numpy()[0]\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Code\")\n",
    "    plt.imshow(code.reshape([code.shape[-1]//2,-1]))\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(reco.clip(0,1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = evaluate(X_test)\n",
    "print(\"Final MSE:\",score)\n",
    "\n",
    "encoder = list(autoencoder.children())[0]\n",
    "decoder = list(autoencoder.children())[1]\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отправляемся глубже\n",
    "\n",
    "PCA уже даёт неплохие результаты, но мы в состоянии добиться лучшего. В этот раз мы построим глубокий автоэнкодер... добавив больше слоёв.\n",
    "\n",
    "В частности, энкодер и декодер оба должны иметь как минимум 3 слоя. Допускается использование любой активационной функции и любого количества нейронов в слоях (кроме слоя с кодом). Сеть не должна быть слишком большой, чтобы её тренировка занимала не так много времени.\n",
    "\n",
    "![layers](https://pbs.twimg.com/media/CYggEo-VAAACg_n.png:small)\n",
    "\n",
    "Проверьте:\n",
    "* Не должно быть скрытых слоёв размером меньше, чем слой с кодом (выходной слой энкодера).\n",
    "* Не забывайте добавлять нелинейность между полносвязными слоями.\n",
    "* Использование свёрточных сетей допускается, но не является необходимым. Чтобы отменить операцию свёртки используйте nn.ConvTranspose2d, операцию подвыборки (pooling) - nn.UpsamplingBilinear2d.\n",
    "* Добавление активационной функции после слоя с кодом допускается, но не является строго необходимым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepEncoder(nn.Module):\n",
    "    def __init__(self, img_shape, code_size=32):\n",
    "        super(DeepEncoder, self).__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            < Your code here: define encoder architecture as per \n",
    "            instructions above>\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), -1)\n",
    "        input = self.enc(input)\n",
    "        return input\n",
    "    \n",
    "    \n",
    "class DeepDecoder(nn.Module):\n",
    "    def __init__(self, img_shape, code_size=32):\n",
    "        super(DeepDecoder, self).__init__()\n",
    "        self.dec = nn.Sequential(\n",
    "            < Your code here: define decoder architecture as per \n",
    "            instructions above>\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = self.dec(input)\n",
    "        input = input.view((input.size(0),) + img_shape)\n",
    "        return input\n",
    "    \n",
    "    \n",
    "class DeepAutoencoder(nn.Module):\n",
    "    def __init__(self, img_shape, code_size=32):\n",
    "        super(DeepAutoencoder, self).__init__()\n",
    "        self.encoder = DeepEncoder(img_shape, code_size)\n",
    "        self.decoder = Decoder(img_shape, code_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = self.encoder(input)\n",
    "        input = self.decoder(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check autoencoder shapes along different code_sizes\n",
    "for code_size in [1,8,32,128,512,1024]:\n",
    "    encoder = DeepEncoder(img_shape, code_size)\n",
    "    decoder = DeepDecoder(img_shape, code_size)\n",
    "    encoder_layers = list(encoder.children())[0]\n",
    "    decoder_layers = list(decoder.children())[0]\n",
    "    print(\"Testing code size %i\" % code_size)\n",
    "    assert list(encoder_layers.children())[-1].out_features==code_size, \"encoder must output a code of required size\"\n",
    "    assert list(decoder_layers.children())[-1].out_features==np.prod(img_shape), \"decoder must output an image of valid shape\"\n",
    "    assert len(list(encoder.parameters()))>=6,     \"encoder must contain at least 3 dense layers\"\n",
    "    assert len(list(decoder.parameters()))>=6,     \"decoder must contain at least 3 dense layers\"\n",
    "    \n",
    "    for layer in encoder_layers:\n",
    "        if type(layer) == nn.Linear:\n",
    "            assert layer.out_features >= code_size, \"Encoder layer %s is smaller than bottleneck\"%(layer)\n",
    "    \n",
    "    for layer in decoder_layers:\n",
    "        if type(layer) == nn.Linear:\n",
    "            assert layer.out_features >= code_size, \"Decoder layer %s is smaller than bottleneck\"%(layer)\n",
    "\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Подсказка:__ Если вы получаете ошибку \"Encoder layer is smaller than bottleneck\", используйте переменную code_size при объявлении промежуточных слоёв. \n",
    "\n",
    "Например, такой слой может содержать code_size*2 нейронов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "code_size = 32\n",
    "\n",
    "autoencoder = DeepAutoencoder(img_shape, code_size)\n",
    "\n",
    "inp_image = Variable(torch.FloatTensor((batch_size,) + img_shape))\n",
    "inp_code = Variable(torch.FloatTensor(batch_size, code_size))\n",
    "\n",
    "if use_cuda:\n",
    "    autoencoder.cuda()\n",
    "    inp_image.cuda()\n",
    "    inp_code.cuda()\n",
    "    \n",
    "autoenc_opt = torch.optim.Adamax(autoencoder.parameters())\n",
    "autoenc_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение может потребовать около 20 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    losses = []\n",
    "    for x_batch in iterate_minibatches(X_train,batch_size=batch_size):\n",
    "        autoencoder.zero_grad()\n",
    "        inp_image.data.resize_(x_batch.size()).copy_(x_batch)\n",
    "        rec = autoencoder(inp_image)\n",
    "        err = autoenc_loss(rec, inp_image)\n",
    "        err.backward()\n",
    "        autoenc_opt.step()\n",
    "        losses.append(err.data[0])\n",
    "    print(\"#%i, Train loss: %.7f\"%(epoch+1,np.mean(losses)),flush=True)\n",
    "\n",
    "    print(\"#%i, Test loss: %.7f\"%(epoch+1,evaluate(X_test)),flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruction_mse = evaluate(X_test)\n",
    "assert reconstruction_mse <= 0.01, \"Compression is too lossy. See tips below.\"\n",
    "print(\"Final MSE:\", reconstruction_mse)\n",
    "\n",
    "encoder = list(autoencoder.children())[0]\n",
    "decoder = list(autoencoder.children())[1]\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Подсказка:__ Если вы получаете ошибку \"Compression to lossy\", вот несколько вещей, которые можно попробовать:\n",
    "\n",
    "* Убедитесь, что процесс обучения сошёлся. Некоторые архитектуры могут потребовать для этого гораздо больше, чем 32 эпохи. Процесс обучения и метрика могут колебаться, но рано или поздно её значания станут достаточно хорошими для прохождения проверки. Можете тренировать сеть столько, сколько для этого потребуется.\n",
    "\n",
    "* Сложность архитектуры. Если у вас уже, например, 152 слоя, и вы всё ещё не проходите проверку, начните с чего-то более простого и постепенно усложняйте архитекруру.\n",
    "\n",
    "* Архитектура. Вы можете использовать любую комбинацию слоёв (включая свёрточные, нормализационные и так далее) до тех пор, пока __выходной слой энкодера содержит только 32 числа на обучающий пример__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Арифметика скрытого представления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    image1,image2 = X_test[np.random.randint(0,len(X_test),size=2)]\n",
    "    code1, code2 = encoder(Variable(torch.from_numpy(np.stack([image1,image2])))).data.numpy()\n",
    "\n",
    "    plt.figure(figsize=[10,4])\n",
    "    for i,a in enumerate(np.linspace(0,1,num=7)):\n",
    "\n",
    "        output_code = code1*(1-a) + code2*(a)\n",
    "        output_code = Variable(torch.from_numpy(output_code[None]))\n",
    "        output_image = decoder(output_code).data.numpy()[0]\n",
    "\n",
    "        plt.subplot(1,7,i+1)\n",
    "        plt.imshow(output_image)\n",
    "        plt.title(\"a=%.2f\"%a)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шумоподавляющие автоэнкодера\n",
    "\n",
    "Превратим нашу модель в шумоподавляющий автоэнкодер.\n",
    "\n",
    "Мы сохраним архитектуру модели неизменной, но внесём изменения в процесс её работы. В частности, мы внесём случайную ошибку в её входные данные перед началом каждой эпохи.\n",
    "\n",
    "Есть много методов зашумления. Мы имплементируем два популярных: добавление гауссового шума и дропаута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_gaussian_noise(X,sigma=0.1):\n",
    "    \"\"\"\n",
    "    adds noise from normal distribution with standard deviation sigma\n",
    "    :param X: image tensor of shape [batch,height,width,3]\n",
    "    \"\"\"\n",
    "    <Your code here>\n",
    "    return X + noise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#noise tests\n",
    "theoretical_std = (X[:100].std()**2 + 0.5**2)**.5\n",
    "our_std = apply_gaussian_noise(X[:100],sigma=0.5).std()\n",
    "assert abs(theoretical_std - our_std) < 0.01, \"Standard deviation does not match it's required value. Make sure you use sigma as std.\"\n",
    "assert abs(apply_gaussian_noise(X[:100],sigma=0.5).mean() - X[:100].mean()) < 0.01, \"Mean has changed. Please add zero-mean noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X[0])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(apply_gaussian_noise(X[:1],sigma=0.01)[0])\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(apply_gaussian_noise(X[:1],sigma=0.1)[0])\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(apply_gaussian_noise(X[:1],sigma=0.5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "code_size=512\n",
    "\n",
    "autoencoder = DeepAutoencoder(img_shape, code_size=code_size)\n",
    "\n",
    "inp_image = Variable(torch.FloatTensor((batch_size,) + img_shape))\n",
    "inp_code = Variable(torch.FloatTensor(batch_size, code_size))\n",
    "\n",
    "if use_cuda:\n",
    "    autoencoder.cuda()\n",
    "    inp_image.cuda()\n",
    "    inp_code.cuda()\n",
    "    \n",
    "autoenc_opt = torch.optim.Adamax(autoencoder.parameters())\n",
    "autoenc_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    print(\"Epoch %i/50, Generating corrupted samples...\"%epoch)\n",
    "    X_train_noise = apply_gaussian_noise(X_train)\n",
    "    X_test_noise = apply_gaussian_noise(X_test)\n",
    "    losses = []\n",
    "    \n",
    "    for x_batch in iterate_minibatches(X_train_noise,batch_size=batch_size):\n",
    "        autoencoder.zero_grad()\n",
    "        inp_image.data.resize_(x_batch.size()).copy_(x_batch)\n",
    "        rec = autoencoder(inp_image)\n",
    "        err = autoenc_loss(rec, inp_image)\n",
    "        err.backward()\n",
    "        autoenc_opt.step()\n",
    "        losses.append(err.data[0])\n",
    "    print(\"#%i, Train loss: %.7f\"%(epoch+1,np.mean(losses)),flush=True)\n",
    "\n",
    "    print(\"#%i, Test loss: %.7f\"%(epoch+1,evaluate(X_test_noise)),flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Замечание:__ Если обучение не сошлось, увеличьте количество итераций.\n",
    "\n",
    "__Дополнительное задание:__ Замените гауссов шум на перекрытие случайных прямогугольников на изображении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "denoising_mse = evaluate(X_test)\n",
    "print(\"Final MSE:\", denoising_mse)\n",
    "\n",
    "encoder = list(autoencoder.children())[0]\n",
    "decoder = list(autoencoder.children())[1]\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск изображений при помощи автоэнкодеров\n",
    "\n",
    "Мы только что обучили сеть, которая преобразует изображение само в себя с ошибкой. Эта задача не столько полезна сама по себе, но она обладает рядом полезных побочных эффектов. Изучим их в действии.\n",
    "\n",
    "В первую очередь мы можем осуществлять поиск изображений. Имея изображения, мы хотим найти похожие используя код в латентном пространстве.\n",
    "\n",
    "Чтобы ускорить процесс поиска, мы будем использовать Locality-Sensitive Hashing с закодированными векторами. Мы будем использовать имплементацию из scikit-learn для простоты. В реальных условиях, вам скорее всего потребуется использовать [специализированные библиотеки](https://erikbern.com/2015/07/04/benchmark-of-approximate-nearest-neighbor-libraries.html) для большей производительности и поддержки дополнительных настроек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_codes(images):\n",
    "    codes = np.zeros([images.shape[0], code_size])\n",
    "    for i, image in enumerate(images):\n",
    "        image = Variable(torch.from_numpy(image[None]))\n",
    "        codes[i] = encoder(image).data.numpy()[0]\n",
    "    return codes\n",
    "\n",
    "images = X_train\n",
    "codes = <encode all images>\n",
    "assert len(codes) == len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LSHForest\n",
    "lshf = LSHForest(n_estimators=50).fit(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_similar(image, n_neighbors=5):\n",
    "    assert image.ndim==3,\"image must be [batch,height,width,3]\"\n",
    "    \n",
    "    image = Variable(torch.from_numpy(image[None]))\n",
    "    code = encoder(image).data.numpy()[0]\n",
    "    \n",
    "    (distances,),(idx,) = lshf.kneighbors(code,n_neighbors=n_neighbors)\n",
    "    \n",
    "    return distances,images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_similar(image):\n",
    "    \n",
    "    distances,neighbors = get_similar(image,n_neighbors=11)\n",
    "    \n",
    "    plt.figure(figsize=[8,6])\n",
    "    plt.subplot(3,4,1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Original image\")\n",
    "    \n",
    "    for i in range(11):\n",
    "        plt.subplot(3,4,i+2)\n",
    "        plt.imshow(neighbors[i])\n",
    "        plt.title(\"Dist=%.3f\"%distances[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#smiles\n",
    "show_similar(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ethnicity\n",
    "show_similar(X_test[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#glasses\n",
    "show_similar(X_test[66])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Есть и много других применений автоэнкодеров.\n",
    "\n",
    "Тем не менее, они не совсем подходят для генерации изображений. Для этого лучше использовать генеративно-состязательные сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
