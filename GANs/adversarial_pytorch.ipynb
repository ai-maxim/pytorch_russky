{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание искусственных лиц при помощи генеративно-состязательных моделей\n",
    "<img src=\"https://www.strangerdimensions.com/wp-content/uploads/2013/11/reception-robot.jpg\" width=320>\n",
    "Мы обучим нейронную сеть генерации правдоподобно выглядящих человеческих лиц во всём их разнообразии: разный внешний вид, выражения лица, аксессуары и так далее. После захвата Земли машинами, лиц больше не останется, и мы хотим сохранить эти данные дла будущих итераций. Жуть...\n",
    "\n",
    "Основано на https://github.com/Lasagne/Recipes/pull/94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "plt.rcParams.update({'axes.titlesize': 'small'})\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "#The following line fetches you two datasets: images, usable for autoencoder training and attributes.\n",
    "#Those attributes will be required for the final part of the assignment (applying smiles), so please keep them in mind\n",
    "from lfw_dataset import fetch_lfw_dataset\n",
    "data,attrs = fetch_lfw_dataset(dimx=36,dimy=36)\n",
    "\n",
    "#preprocess faces\n",
    "data = np.float32(data).transpose([0,3,1,2]) / 255.\n",
    "\n",
    "IMG_SHAPE = data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print random image\n",
    "plt.imshow(data[np.random.randint(data.shape[0])].transpose([1,2,0]),\n",
    "           cmap=\"gray\", interpolation=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основы генеративно-состязательных сетей\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/model.png\" width=320px height=240px>\n",
    "\n",
    "Глубинное обучение довольно простое, не так ли? \n",
    "* Создаём сеть, генерирующую лицо (изображение небольшого размера)\n",
    "* Придумываем __метрику__ того, __насколько это хорошее лицо__\n",
    "* Оптимизируем градиентным спуском :)\n",
    "\n",
    "\n",
    "Единственная проблема заключается в определении того, как отличить хорошо сгенерированное лицо от плохого? В данном случае будет сложно найти специалиста для помощи. \n",
    "\n",
    "__Если мы не можем отличить хорошее лицо от плохого, мы делегируем задачу другой нейронной сети!__\n",
    "\n",
    "Теперь у нас есть две сети:\n",
    "* __G__ (генератор) - принимает на вход случайный шум и пытается сгенерировать пример лица.\n",
    "  * Обозначим его как __G__(z), где z это гауссовский шум.\n",
    "* __D__ (дискриминатор) - принимает на вход пример лица и определяет, является ли оно хорошим или сгенерированным.\n",
    "  * Определяет вероятность того, что ему на вход было подано __настоящее лицо__\n",
    "  * Обозначим его как __D__(x), где x это изображение.\n",
    "  * __D(x)__ это предсказание для настоящего лица и __D(G(z))__ это предсказание для лица, созданного генератором.\n",
    "\n",
    "Прежде чем мы приступим к обучению, давайте создадим обе сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "if use_cuda:\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Not using GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_noise_batch(batch_size):\n",
    "    noise = Variable(torch.randn(batch_size, CODE_SIZE))\n",
    "    return noise.cuda() if use_cuda else noise.cpu()\n",
    "    \n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        nn.Module.__init__(self)\n",
    "        self.shape=shape\n",
    "    def forward(self,input):\n",
    "        return input.view(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CODE_SIZE = 256\n",
    "\n",
    "from itertools import count\n",
    "# automatic layer name maker. Don't do this in production :)\n",
    "ix = ('layer_%i'%i for i in count())\n",
    "\n",
    "generator = nn.Sequential()\n",
    "\n",
    "generator.add_module(next(ix), nn.Linear(CODE_SIZE, 10*8*8))\n",
    "generator.add_module(next(ix), nn.ELU())\n",
    "generator.add_module(next(ix), Reshape([-1, 10, 8, 8]))\n",
    "\n",
    "generator.add_module(next(ix), nn.ConvTranspose2d(10, 64, kernel_size=(5,5)))\n",
    "generator.add_module(next(ix), nn.ELU())\n",
    "generator.add_module(next(ix), nn.ConvTranspose2d(64, 64, kernel_size=(5,5)))\n",
    "generator.add_module(next(ix), nn.ELU())\n",
    "generator.add_module(next(ix), nn.Upsample(scale_factor=2))\n",
    "\n",
    "generator.add_module(next(ix), nn.ConvTranspose2d(64, 32, kernel_size=(5,5)))\n",
    "generator.add_module(next(ix), nn.ELU())\n",
    "generator.add_module(next(ix), nn.ConvTranspose2d(32, 32, kernel_size=(5,5)))\n",
    "generator.add_module(next(ix), nn.ELU())\n",
    "\n",
    "generator.add_module(next(ix), nn.Conv2d(32, 3, kernel_size=(5,5)))\n",
    "\n",
    "if use_cuda: generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_data = generator(sample_noise_batch(5))\n",
    "assert tuple(generated_data.shape)[1:] == IMG_SHAPE, \"generator must output an image of shape %s, but instead it produces %s\"%(IMG_SHAPE,generated_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дискриминатор\n",
    "* Дискриминатор это обычная свёрточная сеть, содержащая свёрточные (convolution) слои и слои субдискретизации (pooling)\n",
    "* Сеть не включает в себя dropout/batchnorm слои чтобы избежать сложностей при обучении.\n",
    "* Мы дополнительно осуществляем регуляризацию предвыходного слоя чтобы предотвратить чрезмерную уверенность дискриминатора при предсказании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_data_batch(batch_size):\n",
    "    idxs = np.random.choice(np.arange(data.shape[0]), size=batch_size)\n",
    "    batch = Variable(torch.FloatTensor(data[idxs]))\n",
    "    return batch.cuda() if use_cuda else batch.cpu()\n",
    "\n",
    "# a special module that converts [batch, channel, w, h] to [batch, units]\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator = nn.Sequential()\n",
    "\n",
    "### YOUR CODE - create convolutional architecture for discriminator\n",
    "### Note: please start simple. A few convolutions & poolings would do, inception/resnet is an overkill\n",
    "\n",
    "discriminator.add_module(\"disc_logit\", nn.Linear(<???>, 1))\n",
    "\n",
    "if use_cuda: discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator(sample_data_batch(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение\n",
    "\n",
    "Мы будем одновременно обучать две сети:\n",
    "* Обучаем __дискриминатор__ чтобы он мог лучше отличать истинные примеры от __текущих__ сгенерированных\n",
    "* Обучаем __генератор__ чтобы обмануть дискриминатор, заставив думать что сгенерированные примеры являются истинными\n",
    "* Поскольку дискриминатор является дифференцируемой нейронной сетью, мы будем обучать обе сети при помощи градиентного спуска.\n",
    "\n",
    "![img](https://s24.postimg.org/cw4nognxx/gan.png)\n",
    "\n",
    "Обучение выполняется итеративно до тех пор, пока дискриминатор будет не в состоянии найти разницу между искусственными и истинными примерами, или пока у вас не закончится терпение.\n",
    "\n",
    "\n",
    "### Советы:\n",
    "* Регуляризуйте выходные веса выходного слоя дискриминатора чтобы предотвратить перекос значений\n",
    "* Обучайте генератор используя __adam__ чтобы ускорить процесс обучения. Обучайте дискриминатор при помощи стохастического градиентного спуска чтобы предотвратить проблемы с моментом.\n",
    "* Больше советов: https://github.com/soumith/ganhacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(noise):\n",
    "    \"\"\"\n",
    "    1. generate data given noise\n",
    "    2. compute log P(real | gen noise)\n",
    "    3. return generator loss (should be scalar)\n",
    "    \"\"\"\n",
    "    generated_data = <generate data given noise>\n",
    "    \n",
    "    disc_on_generated_data = <discriminator's opinion on generated data>\n",
    "    \n",
    "    logp_gen_is_real = F.logsigmoid(disc_on_generated_data)\n",
    "    \n",
    "    loss = - <generator loss>\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = generator_loss(sample_noise_batch(32))\n",
    "\n",
    "print(loss)\n",
    "\n",
    "assert len(loss.shape) == 1 and loss.shape[0] == 1, \"loss must be scalar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_data, generated_data):\n",
    "    \"\"\"\n",
    "    1. compute discriminator's output on real & generated data\n",
    "    2. compute log-probabilities of real data being real, generated data being fake\n",
    "    3. return discriminator loss (scalar)\n",
    "    \"\"\"\n",
    "    disc_on_real_data = <discriminator's opinion on real data>\n",
    "    disc_on_fake_data = <discriminator's opinion on generated data>\n",
    "    \n",
    "    logp_real_is_real = F.logsigmoid(disc_on_real_data)\n",
    "    logp_gen_is_fake = F.logsigmoid(- logp_gen_is_fake)\n",
    "    \n",
    "    loss = <discriminator loss>\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = discriminator_loss(sample_data_batch(32), \n",
    "                   generator(sample_noise_batch(32)))\n",
    "\n",
    "print(loss)\n",
    "\n",
    "assert len(loss.shape) == 1 and loss.shape[0] == 1, \"loss must be scalar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные функции\n",
    "Здесь мы определим ряд функций-помощников, которые позволят получать текущие распределения данных и батчи для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_images(nrow,ncol, sharp=False):\n",
    "    images = generator(sample_noise_batch(batch_size=nrow*ncol))\n",
    "    images = images.data.cpu().numpy().transpose([0,2,3,1])\n",
    "    if np.var(images)!=0:\n",
    "        images = images.clip(np.min(data),np.max(data))\n",
    "    for i in range(nrow*ncol):\n",
    "        plt.subplot(nrow,ncol,i+1)\n",
    "        if sharp:\n",
    "            plt.imshow(images[i],cmap=\"gray\", interpolation=\"none\")\n",
    "        else:\n",
    "            plt.imshow(images[i],cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def sample_probas(batch_size):\n",
    "    plt.title('Generated vs real data')\n",
    "    D_real = F.sigmoid(discriminator(sample_data_batch(batch_size)))\n",
    "    generated_data_batch = generator(sample_noise_batch(batch_size))\n",
    "    D_fake = F.sigmoid(discriminator(generated_data_batch))\n",
    "    \n",
    "    plt.hist(D_real.data.cpu().numpy(),\n",
    "             label='D(x)', alpha=0.5,range=[0,1])\n",
    "    plt.hist(D_fake.data.cpu().numpy(),\n",
    "             label='D(G(z))',alpha=0.5,range=[0,1])\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "Основной цикл.\n",
    "Мы циклически обучаем генератор и дискриминатор, и просматриваем результаты каждые N итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizers\n",
    "disc_opt = torch.optim.SGD(discriminator.parameters(), lr=5e-3)\n",
    "gen_opt = torch.optim.Adam(generator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from tqdm import tnrange\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in tnrange(50000):\n",
    "    \n",
    "    # Train discriminator\n",
    "    for i in range(5):\n",
    "        real_data = sample_data_batch(batch_size)\n",
    "        fake_data = generator(sample_noise_batch(batch_size))\n",
    "        loss = discriminator_loss(real_data, fake_data)\n",
    "        disc_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        disc_opt.step()\n",
    "        \n",
    "    # Train generator\n",
    "    noise = sample_noise_batch(batch_size)\n",
    "    loss = generator_loss(noise)\n",
    "    gen_opt.zero_grad()\n",
    "    loss.backward()\n",
    "    gen_opt.step()\n",
    "    \n",
    "    if epoch %100==0:\n",
    "        display.clear_output(wait=True)\n",
    "        sample_images(2,3,True)\n",
    "        sample_probas(1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#The network was trained for about 15k iterations. \n",
    "#Training for longer yields MUCH better results\n",
    "plt.figure(figsize=[16,24])\n",
    "sample_images(16,8)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
