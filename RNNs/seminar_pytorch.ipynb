{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация имён при помощи реукррентных нейронных сетей.\n",
    "\n",
    "Мы попробуем разобраться в устройстве рекуррентных нейронных сетей, рассмотрев ряд \"игрушечных\" примеров задач.\n",
    "\n",
    "У вас возникали проблемы с поиском переменной при программировании? Посмотрим, насколько сложно придумать имя для сына или дочери. Очевидно, люди недостаточно хорошо разбираются в том, какое имя подойдёт для ребёнка, поэтому мы доверим эту задачу рекуррентной нейронной сети.\n",
    "\n",
    "Начнём с импорта необходимых библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные\n",
    "Набор данных содержит примерно 8 тысяч имён землян из разных культур, написанных латиницей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "start_token = \" \"\n",
    "\n",
    "with open(\"names.txt\") as f:\n",
    "    lines = f.read()[:-1].split('\\n')\n",
    "    lines = [start_token + line for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('n samples = ',len(lines))\n",
    "for x in lines[::1000]:\n",
    "    print (x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(map(len, lines))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, lines)),bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка текста\n",
    "\n",
    "Сначала нам нужно собрать \"словарь\" уникальных знаков, или уникальных символов. После этого входные данные могут быть представленны как последовательности индексов символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all unique characters go here\n",
    "tokens = <all unique characters in the dataset>\n",
    "\n",
    "tokens = list(tokens)\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print ('num_tokens = ', num_tokens)\n",
    "\n",
    "assert 50 < num_tokens < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перевод символов в целые числа\n",
    "\n",
    "Torch создан для обработки чисел, а не строк.\n",
    "Для обучения нейронной сети необходимо заменить символы на их индексы в общем списке символов.\n",
    "\n",
    "Создадим словарь, который позволит осуществить подобное преобразование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = <dictionary of symbol -> its identifier (index in tokens list)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_matrix(lines, max_len=None, pad=token_to_id[' '], dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = [token_to_id[c] for c in lines[i]]\n",
    "        lines_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        lines_ix = np.transpose(lines_ix)\n",
    "\n",
    "    return lines_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Премер: преобразование 4 случайных имён в матрицы, дозаполнение нулями\n",
    "print('\\n'.join(lines[::2000]))\n",
    "print(to_matrix(lines[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекуррентная нейронная сеть\n",
    "\n",
    "Рекуррентная нейронная сеть может быть представлена как последовательное применение полносвязного слоя к входным данным $x_t$ и предыдущему состоянию РНН $h_t$. Именно это мы и сделаем.\n",
    "<img src=\"./rnn.png\" width=480>\n",
    "\n",
    "Поскольку мы обучаем языковую модель, в ней должны быть:\n",
    "* Слой представления (embedding), который преобразует идентификатор символа x_t в вектор.\n",
    "* Выходной слой, предсказывающий вероятности следующей фонемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, variable containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, variable containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        # get vector embedding of x\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # compute next hidden state using self.rnn_update\n",
    "        # hint: use torch.cat(..., dim=...) for concatenation\n",
    "        h_next = ###YOUR CODE HERE\n",
    "        \n",
    "        h_next = F.tanh(h_next)\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = ###YOUR CODE\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return Variable(torch.zeros(batch_size, self.num_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл РНН\n",
    "\n",
    "После того как мы определили единичный шаг РНН, мы можем циклично применять его для получения предсказаний для каждого шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in lines_ix\n",
    "    :param lines_ix: an int32 matrix of shape [batch, time], output of to_matrix(lines)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ix = to_matrix(lines[:5])\n",
    "batch_ix = Variable(torch.LongTensor(batch_ix))\n",
    "\n",
    "logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "\n",
    "assert isinstance(logp_seq, Variable) and torch.max(logp_seq).data.numpy() <= 0\n",
    "assert tuple(logp_seq.size()) ==  batch_ix.size() + (num_tokens,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция правдоподобия и градиенты\n",
    "\n",
    "Мы можем обучить нейронную сеть минимизировать перекрёстную энтропию (максимизировать логарифмическую функцию правдоподобия) с истинным распределением следующих символов.\n",
    "\n",
    "Чтобы осуществить подобный расчёт в векторизированной форме, возьмём `batch_ix[:, 1:]` - мартицу идентификаторов символов, смещённых на i шагов влево. Таким образом, i-й символ будет являться следующим символом для i-ой операции предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_logp = logp_seq[:, :-1]\n",
    "actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "\n",
    "loss = -logp_next.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in char_rnn.parameters():\n",
    "    assert w.grad is not None and torch.max(torch.abs(w.grad)).data.numpy() != 0, \\\n",
    "        \"Loss is not differentiable w.r.t. a weight with shape %s. Check forward method.\" % (w.size(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл обучения\n",
    "\n",
    "Мы будем обучать символьную РНН точно так же, как и любую другую модель глубинного обучения: стохастическим градиентным спуском для минибатчей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "char_rnn = CharRNNCell()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(lines, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = Variable(torch.LongTensor(batch_ix))\n",
    "    \n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    <YOUR CODE>\n",
    "    \n",
    "    loss = ###YOUR CODE\n",
    "    \n",
    "    # train with backprop\n",
    "    <YOUR CODE>\n",
    "    \n",
    "    history.append(loss.data.numpy()[0])\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### РНН: сэмплирование\n",
    "После обучения РНН можно приступать к генерации примеров.\n",
    "Для этого пригодится функция шага РНН, определённая в `char_rnn.forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    x_sequence = Variable(torch.LongTensor([x_sequence]))\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, -1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(num_tokens,p=p_next)\n",
    "        next_ix = Variable(torch.LongTensor([[next_ix]]))\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    print(generate_sample(char_rnn, seed_phrase=' Deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуйте!\n",
    "Вы только что создали рекуррентную языковую модель, способную осуществлять генерацию любого вида последовательностей. Есть много видов данных, к которым она может быть применена:\n",
    "\n",
    "* Рассказы/стихи/песни вашего любимого автора\n",
    "* Новостные заголовки\n",
    "* Исходный код Linux или Tensorflow\n",
    "* Молекулы в формате [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system)\n",
    "* Музыка в виде нот/аккордов\n",
    "* Названия из каталогов IKEA\n",
    "* Имена покемонов\n",
    "* Карты из Magic, the Gathering / Hearthstone\n",
    "\n",
    "Если вы хотите попробовать что-то из этого, обратите внимание на:\n",
    "* Сейчас данные представлены в виде последовательности строк, а рассказ может быть представлен как последовательность предложений. Также можно изменить весь процесс предварительной обработки данных.\n",
    "* Некоторые датасеты находятся в свободном доступе, другие могут быть собраны из открытых источников. Попробуйте использовать `Selenium` или `Scrapy` для этого.\n",
    "* Проверьте, что MAX_LENGTH корректно настроена для датасетов большего размера. Ниже представлен дополнительный раздел о динамических РНН.\n",
    "* Более сложные задачи требуют большей архитектуры РНН. Попробуйте использовать больше нейронов или больше слоёв. Также может потребоваться больше итераций обучения.\n",
    "* Долгосрочные зависимости в музыке, рассказах или молекулярной структуре лучше обрабатывать при помощи LSTM или GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Более серьёзно\n",
    "\n",
    "Только что мы вручную создали низкоуровневую имплементацию РНН. Тем не менее, вряд ли стоит переписывать её с нуля для каждой задачи.\n",
    "\n",
    "Как вы могли догадаться, в Torch есть решение данной проблемы. Присутствуют две опции:\n",
    "* `nn.RNNCell(emb_size, rnn_num_units)` - представляет собой единичный шаг РНН наподобие имплементированного выше. По сути, является комбинацией слоёв concat, linear и tanh.\n",
    "* `nn.RNN(emb_size, rnn_num_units)` - Полностью реализует цикл РНН.\n",
    "\n",
    "Другими опциями являются `nn.LSTMCell` или `nn.LSTM`, `nn.GRUCell` или `nn.GRU` и так далее.\n",
    "\n",
    "В данном примере мы перепишем символьную РНН и цикл РНН используя API высокого уровня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNNLoop(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, rnn_num_units, batch_first=True)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x, Variable) and isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, _ = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp\n",
    "    \n",
    "model = CharRNNLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the model applies over the whole sequence\n",
    "batch_ix = to_matrix(sample(lines, 32), max_len=MAX_LENGTH)\n",
    "batch_ix = Variable(torch.LongTensor(batch_ix))\n",
    "\n",
    "logp_seq = model(batch_ix)\n",
    "\n",
    "# compute loss. This time we use nll_loss with some duct tape\n",
    "loss = F.nll_loss(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n",
    "                  batch_ix[:, :-1].contiguous().view(-1))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Другой пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CharLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements something like CharRNNCell, but with LSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        self.emb = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        (prev_h, prev_c) = prev_state\n",
    "        (next_h, next_c) = self.lstm(self.emb(x), (prev_h, prev_c))\n",
    "        logits = self.rnn_to_logits(next_h)\n",
    "        \n",
    "        return (next_h, next_c), F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" LSTM has two state variables, cell and hid \"\"\"\n",
    "        return Variable(torch.zeros(batch_size, self.num_units)), Variable(torch.zeros(batch_size, self.num_units))\n",
    "    \n",
    "char_lstm = CharLSTMCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_ix = to_matrix(sample(lines, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = Variable(torch.LongTensor(batch_ix.tolist()))\n",
    "\n",
    "    logp_seq = rnn_loop(char_lstm, batch_ix)\n",
    "\n",
    "    # compute loss. This time we use nll_loss with some duct tape\n",
    "    loss = F.nll_loss(logp_seq[:, 1:].contiguous().view(-1, num_tokens), \n",
    "                      batch_ix[:, :-1].contiguous().view(-1))\n",
    "\n",
    "    # train with backprop\n",
    "    char_rnn.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "#     print(loss.size())\n",
    "#     assert loss.size()\n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Дополнительное задание: __ Имплементируйте модель, использующую два слоя LSTM (вторая LSTM использует результат первой в качестве входных значений) и обучите её на ваших данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
